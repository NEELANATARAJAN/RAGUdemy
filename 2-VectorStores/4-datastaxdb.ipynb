{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6373a55b",
   "metadata": {},
   "source": [
    "# DataStax Astra DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4d9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import DB libaries\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Import langchain core and community libraries\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06fa5c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8fbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['ASTRA_DB_APPLICATION_TOKEN'] = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "os.environ['ASTRA_DB_API_ENDPOINT'] = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "os.environ['ASTRA_DB_KEYSPACE'] = os.getenv(\"ASTRA_DB_KEYSPACE\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa16f45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x14e1ec7d0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x14e1ec890>, model='text-embedding-3-small', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenAI Embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4ab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents.\n"
     ]
    }
   ],
   "source": [
    "# Load documents from the data directory\n",
    "loader=DirectoryLoader(\"./data/\", glob=\"*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ba8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 5 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=50, \n",
    "    length_function=len,\n",
    "    separators=[' ']\n",
    "    )\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90aa1d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_astradb.vectorstores.AstraDBVectorStore object at 0x14e1e5410>\n",
      "Documents with 5 chunks added to AstraDB vector store.\n"
     ]
    }
   ],
   "source": [
    "# Create AstraDB Vector store\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"rag_udemy\",\n",
    "    embedding=embeddings,\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    namespace=os.getenv(\"ASTRA_DB_KEYSPACE\"),\n",
    ")\n",
    "print(vector_store)\n",
    "vector_store.add_documents(chunks)\n",
    "print(f\"Documents with {len(chunks)} chunks added to AstraDB vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7850dbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['AstraDBVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_astradb.vectorstores.AstraDBVectorStore object at 0x14e1e5410>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={'k':3})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b8cece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x14f3aced0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1601428d0>, model_name='llama-3.3-70b-versatile', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0672b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='You are a helpful AI assistant. Answer the question based on the provided context.\\nIf you cannot find the answer in the context, simply state that you do not have enough information. \\nDo not make up an answer.\\n\\nContext: \\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:'), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RAG Prompt Template\n",
    "prompt_template = \"\"\"You are a helpful AI assistant. Answer the question based on the provided context.\n",
    "If you cannot find the answer in the context, simply state that you do not have enough information. \n",
    "Do not make up an answer.\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d7daeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['AstraDBVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_astradb.vectorstores.AstraDBVectorStore object at 0x14e1e5410>, search_kwargs={'k': 3})\n",
       "           | RunnableLambda(format_context),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='You are a helpful AI assistant. Answer the question based on the provided context.\\nIf you cannot find the answer in the context, simply state that you do not have enough information. \\nDo not make up an answer.\\n\\nContext: \\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x14f3aced0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1601428d0>, model_name='llama-3.3-70b-versatile', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=1000)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RAG Chain\n",
    "def format_context(docs) -> str:\n",
    "    \"\"\" Format retrieved documents into a single context string.\"\"\"\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_context,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c0720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is deep learning?\n",
      "Response: Deep learning is a subset of machine learning based on artificial neural networks, which are inspired by the human brain and consist of layers of interconnected nodes.\n"
     ]
    }
   ],
   "source": [
    "# Test RAG Chain with a query\n",
    "query = \"What is deep learning?\"\n",
    "response = rag_chain.invoke(query)\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "077428a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Question: What is deep learning?\n",
      "\n",
      "\n",
      "Retrieved 3 documents\n",
      "\n",
      "Document 1: Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artifi...\n",
      "\n",
      "Document 2: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enab...\n",
      "\n",
      "Document 3: Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between ...\n",
      "\n",
      "Response: Deep learning is a subset of machine learning based on artificial neural networks, which are inspired by the human brain and consist of layers of interconnected nodes.\n",
      "\n",
      "============================================================\n",
      "Question: What is machine learning?\n",
      "\n",
      "\n",
      "Retrieved 3 documents\n",
      "\n",
      "Document 1: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enab...\n",
      "\n",
      "Document 2: Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artifi...\n",
      "\n",
      "Document 3: Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between ...\n",
      "\n",
      "Response: Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.\n",
      "\n",
      "============================================================\n",
      "Question: What are the types of machine learning?\n",
      "\n",
      "\n",
      "Retrieved 3 documents\n",
      "\n",
      "Document 1: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enab...\n",
      "\n",
      "Document 2: Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artifi...\n",
      "\n",
      "Document 3: data. Reinforcement learning learns through \n",
      "    interaction with an environment using rewards and p...\n",
      "\n",
      "Response: The three main types of machine learning are: \n",
      "1. Supervised learning\n",
      "2. Unsupervised learning\n",
      "3. Reinforcement learning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test RAG Chain with a query list\n",
    "queries = [\n",
    "    \"What is deep learning?\",\n",
    "    \"What is machine learning?\",\n",
    "    \"What are the types of machine learning?\"\n",
    "]\n",
    "\n",
    "# Get contexts and responses\n",
    "contexts  = retriever.batch(queries)\n",
    "responses = rag_chain.batch(queries)\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    query: {\"contexts\": context, \"response\": response}\n",
    "    for query, context, response in zip(queries, contexts, responses)\n",
    "}\n",
    "\n",
    "for query, data in results.items():\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Question: {query}\\n\")\n",
    "    print(f\"\\nRetrieved {len(data['contexts'])} documents\")\n",
    "    for i, doc in enumerate(data['contexts'], 1):\n",
    "        print(f\"\\nDocument {i}: {doc.page_content[:100]}...\")\n",
    "    print(f\"\\nResponse: {data['response']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439bbcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Search Results:\n",
      "\n",
      "Result 1: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
      "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through\n",
      "\n",
      "Result 2: Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
      "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
      "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
      "    context and relationships between words in text.\n",
      "\n",
      "Result 3: Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
      "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\n",
      "\n",
      "Similarity Search Results with Scores:\n",
      "\n",
      "Result 1:\t Score: 0.686555\n",
      " Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experience without being explicitly programmed. There are three main \n",
      "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
      "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
      "    learning finds patterns in unlabeled data. Reinforcement learning learns through\n",
      "\n",
      "Result 2:\t Score: 0.67677325\n",
      " Natural Language Processing (NLP)\n",
      "\n",
      "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
      "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
      "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
      "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
      "    context and relationships between words in text.\n",
      "\n",
      "Result 3:\t Score: 0.663418\n",
      " Deep Learning and Neural Networks\n",
      "\n",
      "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
      "    These networks are inspired by the human brain and consist of layers of interconnected \n",
      "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
      "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
      "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Similarity search\n",
    "search_results=vector_store.similarity_search(\"What is artificial intelligence?\", k=3)  \n",
    "print(\"Similarity Search Results:\\n\")\n",
    "for i, doc in enumerate(search_results, 1):\n",
    "    print(f\"Result {i}: {doc.page_content}\\n\")\n",
    "\n",
    "search_results_with_scores=vector_store.similarity_search_with_score(\"What is artificial intelligence?\", k=3)  \n",
    "print(\"Similarity Search Results with Scores:\\n\")\n",
    "for i, (doc, score) in enumerate(search_results_with_scores, 1):\n",
    "    print(f\"Result {i}:\\t Score: {score}\\n {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748268f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
