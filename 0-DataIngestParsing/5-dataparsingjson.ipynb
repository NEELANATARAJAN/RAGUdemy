{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81df455b",
   "metadata": {},
   "source": [
    "## JSON parsing and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ead21d",
   "metadata": {},
   "source": [
    "### JSON file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0999f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.makedirs('data/json_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13a9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample nested JSON data\n",
    "json_data = {\n",
    "  \"Company\": \"TechCorp\",\n",
    "  \"employees\": [\n",
    "    {\n",
    "      \"employee_id\": \"E001\",\n",
    "      \"name\": \"Amit Sharma\",\n",
    "      \"designation\": \"Software Engineer\",\n",
    "      \"skills\": [\"Python\", \"JavaScript\", \"React\"],\n",
    "      \"email\": \"amit.sharma@company.com\",\n",
    "      \"projects\": [\n",
    "        {\n",
    "          \"project_id\": \"P101\",\n",
    "          \"project_name\": \"RAG System\",\n",
    "          \"status\": \"In Progress\"\n",
    "        },\n",
    "        {\n",
    "          \"project_id\": \"P102\",\n",
    "          \"project_name\": \"Data Pipeline\",\n",
    "          \"status\": \"Completed\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"employee_id\": \"E002\",\n",
    "      \"name\": \"Neha Verma\",\n",
    "      \"designation\": \"Data Analyst\",\n",
    "      \"skills\": [\"Python\", \"SQL\", \"Machine Learning\"],\n",
    "      \"email\": \"neha.verma@company.com\",\n",
    "      \"projects\": [\n",
    "        {\n",
    "          \"project_id\": \"P201\",\n",
    "          \"project_name\": \"Sales Forecasting\",\n",
    "          \"status\": \"In Progress\"\n",
    "        },\n",
    "        {\n",
    "          \"project_id\": \"P202\",\n",
    "          \"project_name\": \"Analytics Dashboard\",\n",
    "          \"status\": \"Planning\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"departments\": {\n",
    "    \"engineering\": {\n",
    "        \"head\": \"Mike Johnson\",\n",
    "        \"budget\": 1000000,\n",
    "        \"team_size\": 25\n",
    "  },\n",
    "    \"data_science\": {\n",
    "        \"head\": \"Sara Williams\",\n",
    "        \"budget\": 750000,\n",
    "        \"team_size\": 15\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1e6d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company': 'TechCorp',\n",
       " 'employees': [{'employee_id': 'E001',\n",
       "   'name': 'Amit Sharma',\n",
       "   'designation': 'Software Engineer',\n",
       "   'skills': ['Python', 'JavaScript', 'React'],\n",
       "   'email': 'amit.sharma@company.com',\n",
       "   'projects': [{'project_id': 'P101',\n",
       "     'project_name': 'RAG System',\n",
       "     'status': 'In Progress'},\n",
       "    {'project_id': 'P102',\n",
       "     'project_name': 'Data Pipeline',\n",
       "     'status': 'Completed'}]},\n",
       "  {'employee_id': 'E002',\n",
       "   'name': 'Neha Verma',\n",
       "   'designation': 'Data Analyst',\n",
       "   'skills': ['Python', 'SQL', 'Machine Learning'],\n",
       "   'email': 'neha.verma@company.com',\n",
       "   'projects': [{'project_id': 'P201',\n",
       "     'project_name': 'Sales Forecasting',\n",
       "     'status': 'In Progress'},\n",
       "    {'project_id': 'P202',\n",
       "     'project_name': 'Analytics Dashboard',\n",
       "     'status': 'Planning'}]}],\n",
       " 'departments': {'engineering': {'head': 'Mike Johnson',\n",
       "   'budget': 1000000,\n",
       "   'team_size': 25},\n",
       "  'data_science': {'head': 'Sara Williams',\n",
       "   'budget': 750000,\n",
       "   'team_size': 15}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5ec04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/json_files/company_data.json', 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0453f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON lines format\n",
    "json1_data = [\n",
    "    {\"timestamp\": \"2025-12-12\", \"event\": \"user_login\", \"user_id\": \"E001\"},\n",
    "    {\"timestamp\": \"2025-12-12\", \"event\": \"page_view\", \"user_id\": \"E001\", \"page\": \"/home\"},\n",
    "    {\"timestamp\": \"2025-12-12\", \"event\": \"purchase\", \"user_id\": \"E001\", \"amount\": 99.99}\n",
    "]\n",
    "\n",
    "with open('data/json_files/events.jsonl', 'w') as f:\n",
    "    for item in json1_data:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98286b9",
   "metadata": {},
   "source": [
    "### JSON Processing strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4093b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "from typing import List, Any, Dict\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12863c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: JSONLoader - Extract specific fields.\n",
      "Loaded 2 employee documents.\n",
      "\n",
      "First employee document content:\n",
      "{\"employee_id\": \"E001\", \"name\": \"Amit Sharma\", \"designation\": \"Software Engineer\", \"skills\": [\"Python\", \"JavaScript\", \"React\"], \"email\": \"amit.sharma@company.com\", \"projects\": [{\"project_id\": \"P101\", \"project_name\": \"RAG System\", \"status\": \"In Progress\"}, {\"project_id\": \"P102\", \"project_name\": \"Data Pipeline\", \"status\": \"Completed\"}]}\n",
      "\n",
      "[Document(metadata={'source': '/Users/neeladnatarajan/DSProjects/LLMOps/hw/RAGUdemy/0-DataIngestParsing/data/json_files/company_data.json', 'seq_num': 1}, page_content='{\"employee_id\": \"E001\", \"name\": \"Amit Sharma\", \"designation\": \"Software Engineer\", \"skills\": [\"Python\", \"JavaScript\", \"React\"], \"email\": \"amit.sharma@company.com\", \"projects\": [{\"project_id\": \"P101\", \"project_name\": \"RAG System\", \"status\": \"In Progress\"}, {\"project_id\": \"P102\", \"project_name\": \"Data Pipeline\", \"status\": \"Completed\"}]}'), Document(metadata={'source': '/Users/neeladnatarajan/DSProjects/LLMOps/hw/RAGUdemy/0-DataIngestParsing/data/json_files/company_data.json', 'seq_num': 2}, page_content='{\"employee_id\": \"E002\", \"name\": \"Neha Verma\", \"designation\": \"Data Analyst\", \"skills\": [\"Python\", \"SQL\", \"Machine Learning\"], \"email\": \"neha.verma@company.com\", \"projects\": [{\"project_id\": \"P201\", \"project_name\": \"Sales Forecasting\", \"status\": \"In Progress\"}, {\"project_id\": \"P202\", \"project_name\": \"Analytics Dashboard\", \"status\": \"Planning\"}]}')]\n"
     ]
    }
   ],
   "source": [
    "# Method 1: JSONLoader iwth jq_schema\n",
    "print(\"Method 1: JSONLoader - Extract specific fields.\")\n",
    "\n",
    "# Extract employee information\n",
    "employee_loader = JSONLoader(file_path='data/json_files/company_data.json',\n",
    "jq_schema='.employees[]',\n",
    "text_content=False\n",
    ")\n",
    "\n",
    "employee_docs = employee_loader.load()\n",
    "print(f\"Loaded {len(employee_docs)} employee documents.\\n\")\n",
    "print(f\"First employee document content:\\n{employee_docs[0].page_content}\\n\")\n",
    "print(employee_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8380e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2: JSONLoader - Custom parsing and processing.\n"
     ]
    }
   ],
   "source": [
    "# Method 2: JSONLoader for Custom Parsing and Processing\n",
    "print(\"Method 2: JSONLoader - Custom parsing and processing.\")\n",
    "\n",
    "def smart_json_processor(file_path: str) -> List[Document]:\n",
    "    \"\"\"Process JSON file for intelligent flattening and context preservation.\"\"\"\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # Strategy 1: Create documents for each employee with full context\n",
    "    for emp in data.get('employees', []):\n",
    "        content = f\"Employee ID: {emp['employee_id']}\\n\"\n",
    "        content += f\"Name: {emp['name']}\\n\"\n",
    "        content += f\"Designation: {emp['designation']}\\n\"\n",
    "        content += f\"Email: {emp['email']}\\n\"\n",
    "        content += f\"Skills: {', '.join(emp['skills'])}\\n\"\n",
    "        content += \"Projects:\\n\"\n",
    "        for proj in emp.get('projects', []):\n",
    "            content += f\"  - {proj['project_name']} (Status: {proj['status']})\\n\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                'source': file_path,\n",
    "                'data_type': 'employee_profile',\n",
    "                'employee_id': emp['employee_id'],\n",
    "                'employee_name': emp['name'],\n",
    "                'role': emp['designation']\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba49de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2 smart documents from JSON.\n",
      "\n",
      "\n",
      "Document 1 content:\n",
      "Employee ID: E001\n",
      "Name: Amit Sharma\n",
      "Designation: Software Engineer\n",
      "Email: amit.sharma@company.com\n",
      "Skills: Python, JavaScript, React\n",
      "Projects:\n",
      "  - RAG System (Status: In Progress)\n",
      "  - Data Pipeline (Status: Completed)\n",
      "\n",
      "\n",
      "source: data/json_files/company_data.json\n",
      "data_type: employee_profile\n",
      "employee_id: E001\n",
      "employee_name: Amit Sharma\n",
      "role: Software Engineer\n",
      "\n",
      "Document 2 content:\n",
      "Employee ID: E002\n",
      "Name: Neha Verma\n",
      "Designation: Data Analyst\n",
      "Email: neha.verma@company.com\n",
      "Skills: Python, SQL, Machine Learning\n",
      "Projects:\n",
      "  - Sales Forecasting (Status: In Progress)\n",
      "  - Analytics Dashboard (Status: Planning)\n",
      "\n",
      "\n",
      "source: data/json_files/company_data.json\n",
      "data_type: employee_profile\n",
      "employee_id: E002\n",
      "employee_name: Neha Verma\n",
      "role: Data Analyst\n"
     ]
    }
   ],
   "source": [
    "smart_json_docs = smart_json_processor('data/json_files/company_data.json')\n",
    "print(f\"Processed {len(smart_json_docs)} smart documents from JSON.\\n\")\n",
    "for i in range(len(smart_json_docs)):\n",
    "    print(f\"\\nDocument {i+1} content:\\n{smart_json_docs[i].page_content}\\n\")\n",
    "    for key, value in smart_json_docs[i].metadata.items():\n",
    "        print(f\"{key}: {value}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591b70a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3 event log documents from JSONL.\n",
      "\n",
      "\n",
      "Document 1 content:\n",
      "Timestamp: 2025-12-12\n",
      "Event: user_login\n",
      "User ID: E001\n",
      "\n",
      "\n",
      "source: data/json_files/events.jsonl\n",
      "data_type: event_log\n",
      "event_type: user_login\n",
      "user_id: E001\n",
      "\n",
      "Document 2 content:\n",
      "Timestamp: 2025-12-12\n",
      "Event: page_view\n",
      "User ID: E001\n",
      "Page: /home\n",
      "\n",
      "\n",
      "source: data/json_files/events.jsonl\n",
      "data_type: event_log\n",
      "event_type: page_view\n",
      "user_id: E001\n",
      "\n",
      "Document 3 content:\n",
      "Timestamp: 2025-12-12\n",
      "Event: purchase\n",
      "User ID: E001\n",
      "Amount: 99.99\n",
      "\n",
      "\n",
      "source: data/json_files/events.jsonl\n",
      "data_type: event_log\n",
      "event_type: purchase\n",
      "user_id: E001\n"
     ]
    }
   ],
   "source": [
    "# Home work: Process events JSONL file similarly to extract event logs with context.\n",
    "file_path = 'data/json_files/events.jsonl'\n",
    "with open(file_path, 'r') as f:\n",
    "    event_data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "event_documents = []\n",
    "for event in event_data:\n",
    "    content = f\"Timestamp: {event['timestamp']}\\n\"\n",
    "    content += f\"Event: {event['event']}\\n\"\n",
    "    content += f\"User ID: {event['user_id']}\\n\"\n",
    "    if 'page' in event:\n",
    "        content += f\"Page: {event['page']}\\n\"\n",
    "    if 'amount' in event:\n",
    "        content += f\"Amount: {event['amount']}\\n\"\n",
    "\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\n",
    "            'source': file_path,\n",
    "            'data_type': 'event_log',\n",
    "            'event_type': event['event'],\n",
    "            'user_id': event['user_id']\n",
    "        }\n",
    "    )\n",
    "    event_documents.append(doc)\n",
    "print(f\"\\nProcessed {len(event_documents)} event log documents from JSONL.\\n\")\n",
    "for i in range(len(event_documents)):\n",
    "    print(f\"\\nDocument {i+1} content:\\n{event_documents[i].page_content}\\n\")\n",
    "    for key, value in event_documents[i].metadata.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e406b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
